{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment: Using Spark to mine Astro signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Goal: To find the longest repeating cosmological signal in the captured data\n",
    "\n",
    "###### The datset has a series of signals stored as: ascension (degrees), declination (degrees), time (seconds), frequency (MHz). These are radiofrequency signals captured by an array of instruments scanning a solid angle of the sky. The data is, like almost all real data, a little noisy and has sources of errors. In our case the angular coordinates have 0.1 degrees error, the signal frequency has 0.1 MHZ error and the timestamp error is <0.01s (that is one STD or standard deviation).\n",
    "\n",
    "###### Your job is to find the source with the most signals (that is \"blips\", or entries in the datalog). Your target will be found in the same location (within error) of the sky, on the same frequency (within error) chirping for the most blips, regularly spaced in time during that active period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BigDataAnalysis\").getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from pyspark.sql.functions import udf, col, desc\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and reading the dataset\n",
    "rdd = sc.textFile(\"pulsar.dat\")\n",
    "\n",
    "# Transforming the RDD to a structured format\n",
    "rdd2 = rdd.map(lambda x: x.split(' ')).map(lambda x: [float(x[0]), float(x[1]), float(x[2]), float(x[3])])\n",
    "rounded_rdd = rdd2.map(lambda sublist: [round(sublist[0], 1), round(sublist[1], 1), round(sublist[2], 2), round(sublist[3], 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[88.7, 79.8, 932.71, 1001.0],\n",
       " [90.8, 79.1, 2462.08, 1002.2],\n",
       " [90.9, 78.9, 2457.41, 1002.2],\n",
       " [96.3, 80.4, 803.96, 1002.4],\n",
       " [89.2, 75.9, 916.75, 1004.3],\n",
       " [88.9, 75.7, 921.66, 1004.4],\n",
       " [61.7, 110.4, 1958.6, 1004.4],\n",
       " [61.9, 110.1, 1954.87, 1004.8],\n",
       " [79.6, 60.1, 2984.53, 1008.6],\n",
       " [79.7, 60.1, 2969.28, 1008.7]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_freq = rounded_rdd.sortBy(lambda x:(x[3]))\n",
    "sort_freq.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe                                                                          \n",
    "df = spark.createDataFrame(sort_freq, [\"ascension\", \"declination\", \"time\", \"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an user_defined function where we iterate through a sorted column, and group values that are within 4 standard deviations (0.4) of each other\n",
    "def assign_pivot(value):\n",
    "    global pivot\n",
    "    if round(value, 1) <= round(pivot, 1) + 0.4:\n",
    "            return round(pivot, 1)\n",
    " \n",
    "    else:\n",
    "        pivot = round(value, 1)\n",
    "        return round(pivot, 1)\n",
    " \n",
    "assign_pivot_udf = udf(assign_pivot, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+---------+-------------+\n",
      "|ascension|declination|   time|frequency|new_frequency|\n",
      "+---------+-----------+-------+---------+-------------+\n",
      "|     88.7|       79.8| 932.71|   1001.0|       1001.0|\n",
      "|     90.8|       79.1|2462.08|   1002.2|       1002.2|\n",
      "|     90.9|       78.9|2457.41|   1002.2|       1002.2|\n",
      "|     96.3|       80.4| 803.96|   1002.4|       1002.2|\n",
      "|     89.2|       75.9| 916.75|   1004.3|       1004.3|\n",
      "|     88.9|       75.7| 921.66|   1004.4|       1004.3|\n",
      "|     61.7|      110.4| 1958.6|   1004.4|       1004.3|\n",
      "|     61.9|      110.1|1954.87|   1004.8|       1004.8|\n",
      "|     79.6|       60.1|2984.53|   1008.6|       1008.6|\n",
      "|     79.7|       60.1|2969.28|   1008.7|       1008.6|\n",
      "|     79.8|       60.1|2976.91|   1008.7|       1008.6|\n",
      "|    118.5|       69.5|1556.05|   1009.2|       1009.2|\n",
      "|     68.9|       72.2|2268.91|   1009.2|       1009.2|\n",
      "|    118.7|       69.2|1563.76|   1009.4|       1009.2|\n",
      "|    108.7|      110.4| 299.14|   1009.6|       1009.2|\n",
      "|    108.7|      110.5| 301.26|   1009.8|       1009.8|\n",
      "|     62.0|      119.7| 499.52|   1010.9|       1010.9|\n",
      "|     98.6|      110.7|1963.43|   1010.9|       1010.9|\n",
      "|     98.7|      111.0| 1955.4|   1011.1|       1010.9|\n",
      "|     98.7|      110.8|1959.41|   1011.1|       1010.9|\n",
      "+---------+-----------+-------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#starting for “frequency” first\n",
    " \n",
    "pivot = df.select(\"frequency\").first()[0]\n",
    "df1 = df.withColumn(\"new_frequency\", assign_pivot_udf(df[\"frequency\"]))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+---------+-------------+-------------+\n",
      "|ascension|declination|   time|frequency|new_frequency|new_ascension|\n",
      "+---------+-----------+-------+---------+-------------+-------------+\n",
      "|     59.9|      110.8|1113.25|   1116.7|       1116.7|         59.9|\n",
      "|     59.9|       64.9|1546.98|   1243.1|       1242.9|         59.9|\n",
      "|     59.9|       70.5|2175.44|   1306.2|       1306.2|         59.9|\n",
      "|     59.9|      107.6|3254.65|   2502.8|       2502.8|         59.9|\n",
      "|     59.9|      110.6|1093.51|   3334.7|       3334.4|         59.9|\n",
      "|     59.9|       66.5|1941.39|   3546.1|       3546.0|         59.9|\n",
      "|     59.9|      119.0|3581.48|   4525.6|       4525.6|         59.9|\n",
      "|     59.9|      116.7| 1124.8|   5629.3|       5629.3|         59.9|\n",
      "|     59.9|       95.3|2385.33|   6413.9|       6413.7|         59.9|\n",
      "|     59.9|       89.5|3489.34|   7152.2|       7152.0|         59.9|\n",
      "|     59.9|       96.5|1790.79|   7531.6|       7531.6|         59.9|\n",
      "|     60.0|      110.8|1106.89|   1116.7|       1116.7|         59.9|\n",
      "|     60.0|       68.6|3423.47|   1650.3|       1650.2|         59.9|\n",
      "|     60.0|      107.7|3250.19|   2502.9|       2502.8|         59.9|\n",
      "|     60.0|      110.6|1103.21|   3334.4|       3334.4|         59.9|\n",
      "|     60.0|       66.6|1934.53|   3546.0|       3546.0|         59.9|\n",
      "|     60.0|      112.9| 2687.3|   3792.3|       3792.2|         59.9|\n",
      "|     60.0|      106.0|3323.46|   4638.0|       4638.0|         59.9|\n",
      "|     60.0|      106.1|3316.87|   4638.0|       4638.0|         59.9|\n",
      "|     60.0|       78.3|1824.21|   5002.0|       5002.0|         59.9|\n",
      "+---------+-----------+-------+---------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trying for “ascension” next\n",
    "\n",
    "df1 = df1.sort(\"ascension\")\n",
    "pivot = df1.select(\"ascension\").first()[0]\n",
    "assign_pivot_udf = udf(assign_pivot, DoubleType())\n",
    " \n",
    "df2 = df1.withColumn(\"new_ascension\", assign_pivot_udf(df1[\"ascension\"]))\n",
    "df2 = df2.cache()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------+---------+-------------+-------------+---------------+\n",
      "|ascension|declination|   time|frequency|new_frequency|new_ascension|new_declination|\n",
      "+---------+-----------+-------+---------+-------------+-------------+---------------+\n",
      "|     76.4|       59.9|2601.51|   6051.2|       6051.2|         76.4|           59.9|\n",
      "|     64.7|       60.0|1750.62|   5334.4|       5334.2|         64.4|           59.9|\n",
      "|     74.7|       60.0|2413.95|   7426.7|       7426.4|         74.4|           59.9|\n",
      "|     86.6|       60.0| 452.18|   5466.6|       5466.6|         86.4|           59.9|\n",
      "|    102.7|       60.0| 807.69|   3186.2|       3186.2|        102.4|           59.9|\n",
      "|    118.8|       60.0|2495.26|   4536.9|       4536.8|        118.4|           59.9|\n",
      "|     70.8|       60.1|2014.15|   6850.1|       6850.1|         70.4|           59.9|\n",
      "|     74.8|       60.1|2408.05|   7426.6|       7426.4|         74.4|           59.9|\n",
      "|     75.1|       60.1|3472.79|   3696.5|       3696.5|         74.9|           59.9|\n",
      "|     76.5|       60.1|2605.06|   6051.3|       6051.2|         76.4|           59.9|\n",
      "|     79.6|       60.1|2984.53|   1008.6|       1008.6|         79.4|           59.9|\n",
      "|     79.7|       60.1|2969.28|   1008.7|       1008.6|         79.4|           59.9|\n",
      "|     79.8|       60.1|2976.91|   1008.7|       1008.6|         79.4|           59.9|\n",
      "|     86.3|       60.1| 450.84|   5466.3|       5466.0|         85.9|           59.9|\n",
      "|     89.8|       60.1|1303.68|   1888.0|       1888.0|         89.4|           59.9|\n",
      "|     91.3|       60.1|2172.25|   2239.3|       2239.3|         90.9|           59.9|\n",
      "|     95.2|       60.1|1701.05|   4252.4|       4252.3|         94.9|           59.9|\n",
      "|     98.8|       60.1| 1025.3|   3193.1|       3193.1|         98.4|           59.9|\n",
      "|    106.3|       60.1| 696.58|   6196.2|       6196.2|        105.9|           59.9|\n",
      "|    111.1|       60.1|3537.16|   4642.4|       4642.4|        110.9|           59.9|\n",
      "+---------+-----------+-------+---------+-------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trying for declination next\n",
    "\n",
    "df2 = df2.sort(\"declination\")\n",
    "pivot = df2.select(\"declination\").first()[0]\n",
    "assign_pivot_udf = udf(assign_pivot, DoubleType())\n",
    " \n",
    "df3 = df2.withColumn(\"new_declination\", assign_pivot_udf(df2[\"declination\"]))\n",
    "df3 = df3.cache()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------------+-----+\n",
      "|new_frequency|new_ascension|new_declination|count|\n",
      "+-------------+-------------+---------------+-----+\n",
      "|       2231.1|        104.4|           81.9|   26|\n",
      "|       7877.6|        117.9|           62.9|   18|\n",
      "|       4999.8|         93.9|          114.9|   17|\n",
      "|       6925.4|         86.9|           66.4|   12|\n",
      "|       1413.4|        105.4|           96.4|    9|\n",
      "|       2874.4|         97.9|          107.9|    9|\n",
      "|       3277.0|         60.9|           60.4|    9|\n",
      "|       5448.5|        109.9|           75.4|    8|\n",
      "|       3782.1|         62.9|          105.9|    7|\n",
      "|       7591.8|        118.9|          103.9|    6|\n",
      "|       5783.0|        113.9|           97.9|    6|\n",
      "|       7121.0|        110.4|          108.4|    6|\n",
      "|       5813.2|         98.9|           79.4|    6|\n",
      "|       7886.1|        115.4|           87.9|    6|\n",
      "|       1542.3|         64.9|           85.4|    6|\n",
      "|       4783.8|        117.9|           99.4|    6|\n",
      "|       4915.0|         60.9|           78.9|    6|\n",
      "|       6519.1|         88.4|           90.4|    6|\n",
      "|       2033.2|        119.4|          104.9|    6|\n",
      "|       6858.1|         83.4|           89.4|    5|\n",
      "+-------------+-------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using groupBy function to group signals with similar frequency, ascension, and declination\n",
    "grouped_df = df3.groupBy(\"new_frequency\", \"new_ascension\", \"new_declination\").count().sort(desc(\"count\"))\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of grouped_df, we can see that signals that appear at 2231.1 frequency with 104.4 ascension and 82.1 declination occur the most times (26 times). The next highest number of signals occur around 18 times at 2 different combinations of frequency, ascension, and declination. \n",
    "\n",
    "As long as we can show that there are more than 18 signals happening at the first combination of parameters, in equal intervals, we can confirm that, the first signal will form the longest signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----+---------+-------------+-------------+---------------+\n",
      "|ascension|declination| time|frequency|new_frequency|new_ascension|new_declination|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+\n",
      "|    104.5|       82.1|800.0|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.6|       82.1|802.2|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.0|804.4|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.6|       81.9|808.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.2|811.0|   2231.3|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|813.2|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|815.4|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.7|       82.0|817.6|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.6|       82.0|819.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.8|       82.1|822.0|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.2|824.2|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|828.6|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|830.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|835.2|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.4|       82.2|839.6|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.4|       81.9|841.8|   2231.2|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|844.0|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.2|848.4|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|852.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|855.0|   2231.5|       2231.1|        104.4|           81.9|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df3.filter((col(\"new_frequency\") == \"2231.1\") & (col(\"new_ascension\") == \"104.4\") & (col(\"new_declination\") == \"81.9\"))\n",
    "filtered_df.sort(\"time\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we filter through our dataset with our first combination of parameters, we can see that there is a nice time interval of 2.2 seconds between each signal, but they are not consistent, and we can see some missing timestamps in the data frame. \n",
    "\n",
    "Hence, we are going to expand our range to see if there are any other points that fall in this expanded range(which is just plus/minus 1 of the combinations we have found above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df1 = df3.filter((col(\"new_frequency\") >= 2230.0) & (col(\"new_frequency\") <= 2232.0) & (col(\"new_ascension\") >= 103.0) & (col(\"new_ascension\") <= 105.0) & (col(\"new_declination\") >= 81.0) & (col(\"new_declination\") <= 83.0))\n",
    "filtered_df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expansion of range gave 34 counts, which is more than 26 counts we got initially. This is where most of our missing timestamps could been hidden/can be found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----+---------+-------------+-------------+---------------+\n",
      "|ascension|declination| time|frequency|new_frequency|new_ascension|new_declination|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+\n",
      "|    104.4|       81.9|841.8|   2231.2|       2231.1|        104.4|           81.9|\n",
      "|    104.6|       81.9|808.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.4|       82.0|863.8|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.0|859.4|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.0|804.4|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.0|837.4|   2231.6|       2231.6|        104.4|           81.9|\n",
      "|    104.6|       82.0|819.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.7|       82.0|817.6|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.4|       82.1|857.2|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|813.2|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|852.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|830.8|   2231.4|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|835.2|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|844.0|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|815.4|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|828.6|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|800.0|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|855.0|   2231.5|       2231.1|        104.4|           81.9|\n",
      "|    104.5|       82.1|870.4|   2231.6|       2231.6|        104.4|           81.9|\n",
      "|    104.5|       82.1|806.6|   2231.7|       2231.6|        104.4|           81.9|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df1 = df3.filter(\n",
    "    (col(\"new_frequency\") >= 2230.0) & (col(\"new_frequency\") <= 2232.0) &\n",
    "    (col(\"new_ascension\") >= 103.0) & (col(\"new_ascension\") <= 105.0) &\n",
    "    (col(\"new_declination\") >= 81.0) & (col(\"new_declination\") <= 83.0)\n",
    ")\n",
    "\n",
    "filtered_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using Pyspark, we are going to use an in-built Pyspark function (F.lag) to calculate the time interval between each timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----+---------+-------------+-------------+---------------+-------------+\n",
      "|ascension|declination| time|frequency|new_frequency|new_ascension|new_declination|time_interval|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+-------------+\n",
      "|    104.5|       82.1|800.0|   2231.5|       2231.1|        104.4|           81.9|         NULL|\n",
      "|    104.6|       82.1|802.2|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.0|804.4|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|806.6|   2231.7|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.6|       81.9|808.8|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.2|811.0|   2231.3|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|813.2|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|815.4|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.7|       82.0|817.6|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.6|       82.0|819.8|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.8|       82.1|822.0|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.2|824.2|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.6|       82.1|826.4|   2231.6|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|828.6|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|830.8|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.8|       82.2|833.0|   2231.6|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|835.2|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.0|837.4|   2231.6|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.4|       82.2|839.6|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.4|       81.9|841.8|   2231.2|       2231.1|        104.4|           81.9|          2.2|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define UDF\n",
    "def calculate_interval(value, previous_value):\n",
    "    if previous_value is not None:\n",
    "        return round(value - previous_value, 1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "calculate_interval_udf = udf(calculate_interval, DoubleType())\n",
    "window_spec = Window.orderBy(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----+---------+-------------+-------------+---------------+-------------+\n",
      "|ascension|declination| time|frequency|new_frequency|new_ascension|new_declination|time_interval|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+-------------+\n",
      "|    104.5|       82.1|800.0|   2231.5|       2231.1|        104.4|           81.9|         NULL|\n",
      "|    104.6|       82.1|802.2|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.0|804.4|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|806.6|   2231.7|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.6|       81.9|808.8|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.2|811.0|   2231.3|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|813.2|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|815.4|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.7|       82.0|817.6|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.6|       82.0|819.8|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.8|       82.1|822.0|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.2|824.2|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.6|       82.1|826.4|   2231.6|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|828.6|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|830.8|   2231.4|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.8|       82.2|833.0|   2231.6|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.1|835.2|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.5|       82.0|837.4|   2231.6|       2231.6|        104.4|           81.9|          2.2|\n",
      "|    104.4|       82.2|839.6|   2231.5|       2231.1|        104.4|           81.9|          2.2|\n",
      "|    104.4|       81.9|841.8|   2231.2|       2231.1|        104.4|           81.9|          2.2|\n",
      "+---------+-----------+-----+---------+-------------+-------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the withColumn operation\n",
    "final_df = filtered_df1.withColumn(\n",
    "    \"time_interval\",\n",
    "    calculate_interval_udf(col(\"time\"), F.lag(col(\"time\")).over(window_spec))\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output for final_df above, we can see that the time difference is 2.2 for all the timestamps (look at the \"time interval\" column). This shows us that these signals are all occurring at equal time intervals (i.e. they are all the same signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Answer: There are 34blips at location 104, 82 degrees with a frequency of 2231MHZ and a period of 2.2 seconds interval "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
